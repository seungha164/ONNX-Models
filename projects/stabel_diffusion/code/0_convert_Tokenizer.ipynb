{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 97,  32, 115, 109, 105, 108, 101,  32,  99,  97, 116])\n"
     ]
    }
   ],
   "source": [
    "# 1. 아스키 코드화\n",
    "string = \"a smile cat\"\n",
    "ascii_codes = np.array([ord(char) for char in string])\n",
    "ascii_codes = torch.tensor(ascii_codes)\n",
    "print(ascii_codes)  # 출력: [72 101 108 108 111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 97,  32, 115, 109, 105, 108, 101,  32,  99,  97, 116,  -1,  -1,  -1,\n",
       "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "          -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
       "          -1,  -1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 나머지 '-1'로 채워서, [1,100] 사이즈의 tensor화\n",
    "arr = torch.full((1, 100), -1)\n",
    "arr[0, :ascii_codes.size(0)] = ascii_codes\n",
    "print(arr.shape)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 넣기\n",
    "from simple_tokenizer import SimpleTokenizer as _Tokenizer\n",
    "_tokenizer = _Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a smile cat']\n",
      "[[49406, 320, 3490, 2368, 49407]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[49406,   320,  3490,  2368, 49407,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TokenizerModule(nn.Module):\n",
    "    def __init__(self, _tokenizer, device):\n",
    "        super().__init__()\n",
    "        self.tokenizer = _tokenizer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        texts = [''.join([chr(value) for value in x[x!=-1]])]\n",
    "        print(texts)\n",
    "        sot_token = self.tokenizer.encoder[\"<|startoftext|>\"]       # 49407\n",
    "        eot_token = self.tokenizer.encoder[\"<|endoftext|>\"]         # 49406\n",
    "        all_tokens = [[sot_token] + _tokenizer.encode(text) + [eot_token] for text in texts]\n",
    "        print(all_tokens)\n",
    "        result = torch.zeros(len(all_tokens), 77, dtype=torch.int)\n",
    "        for i, tokens in enumerate(all_tokens):\n",
    "            if len(tokens) > 77:\n",
    "                tokens = tokens[:77]\n",
    "                tokens[-1] = eot_token\n",
    "            result[i, :len(tokens)] = torch.tensor(tokens)\n",
    "        return result\n",
    "tz = TokenizerModule(_tokenizer, device)\n",
    "tz(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "from onnxruntime.quantization import QuantType\n",
    "from onnxruntime.quantization.quantize import quantize_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a smile cat']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[''.join([chr(value) for value in arr[arr!=-1]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1824985/3738819508.py:10: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  re = self.tokenizer.encode(''.join([chr(_i) for _i in x]))\n",
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n",
      "WARNING:root:Inference failed or unsupported type to quantize for tensor '/NonZero_output_0', type is tensor_type {\n",
      "  elem_type: 7\n",
      "  shape {\n",
      "    dim {\n",
      "      dim_value: 2\n",
      "    }\n",
      "    dim {\n",
      "      dim_param: \"unk__0\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "class TokenizerModule(nn.Module):\n",
    "    def __init__(self, _tokenizer, device):\n",
    "        super().__init__()\n",
    "        self.tokenizer = _tokenizer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x[x != -1]\n",
    "        llen = 77 - x.shape[0]\n",
    "        result = torch.zeros(1, x.shape[0] + llen, dtype=torch.int64)\n",
    "        re = self.tokenizer.encode(''.join([chr(_i) for _i in x]))\n",
    "        result[0][0] = 49407\n",
    "        for i in range(len(re)):\n",
    "            result[0][i+1] = re[i]\n",
    "        result[0][i+2] = 49406\n",
    "        return result\n",
    "\n",
    " # onnx conversion\n",
    "torch.onnx.export(\n",
    "    model               =   TokenizerModule(_tokenizer, device),                            # 실행될 모델\n",
    "    args                =   (arr),        # 모델 입력값(tuple or 여러 입력값)\n",
    "    f                   =   './tokenizer.onnx',                     # 모델 저장 경로\n",
    "    export_params       =   True,                 # 모델 파일 안에 학습된 모델 가중치 저장 여부\n",
    "    opset_version       =   14,                   # 모델 변환할 때 사용할 onnx 버전\n",
    "    do_constant_folding =   True,         # 최적화시 상수폴딩 사용할지 여부\n",
    "    input_names     =   ['input'],\n",
    "    output_names    =   [\"output\"],\n",
    "    dynamic_axes    =   {\n",
    "        'input'     : {0 : 'batch_size'},    # 가변적인 길이를 가진 차원\n",
    "    }\n",
    ") \n",
    "# model quantization\n",
    "quantize_dynamic(\n",
    "    model_input     =   './tokenizer.onnx', \n",
    "    model_output    =   './tokenizer_quant.onnx', \n",
    "    per_channel     =   False,\n",
    "    reduce_range    =   False,\n",
    "    weight_type     =   QuantType.QUInt8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### ONNX-Runtime Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input names: ['input']\n",
      "Output names: ['output']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model_path = './tokenizer.onnx'\n",
    "session = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Print the input names and shapes\n",
    "input_names = [input.name for input in session.get_inputs()]\n",
    "output_names = [output.name for output in session.get_outputs()]\n",
    "\n",
    "print(\"Input names:\", input_names)\n",
    "print(\"Output names:\", output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 77)\n",
      "[[49407   320  3490  2368 49406     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# test running\n",
    "ort_inputs  = {'input': np.array(arr)}\n",
    "ort_outputs = session.run(None, ort_inputs)\n",
    "print(ort_outputs[0].shape)\n",
    "print(ort_outputs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
